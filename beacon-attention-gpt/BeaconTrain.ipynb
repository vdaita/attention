{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f95309b-75c8-4fa2-a45f-2ca4f8c3ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.3)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.32.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (2.20.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers accelerate datasets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c9b5c3-96a3-48ca-80b5-3fd7504f9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, get_scheduler\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ce4a3a-634b-4ee4-ba0f-52d8789007dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_embedding = True\n",
    "use_custom_attn_mask = True\n",
    "num_epochs = 1\n",
    "window_size = 2\n",
    "batch_size = 64\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0748309c-5d60-4b3b-b491-c74366c9714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff272c6d-7292-4e43-bd09-57bbdd855bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/learn/nlp-course/en/chapter7/6?fw=pt\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    "\n",
    "def causal_lm_loss(inputs, logits, alpha=1.0):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduce=False)\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "    # Calculate average\n",
    "    loss = loss_per_sample.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86cd96b6-aca4-4c8c-9070-f9f854d4c012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0fed593bf04490be3026e7b7d73d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa295b3881414aee87c353471846f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=block_size,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == block_size:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "ds = load_dataset(\"roneneldan/TinyStories\")\n",
    "tokenized_ds = ds.map(tokenize, batched=True, batch_size=batch_size, num_proc=4, remove_columns=ds[\"train\"].column_names)\n",
    "tokenized_ds.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc7b010-eac2-4359-9ded-88f02a150cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_ds[\"train\"].select(list(range(128))), batch_size=64, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_ds[\"validation\"].select(list(range(64))), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3120f687-4691-494e-ae2f-cbe18d980f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 0.1\n",
    "\n",
    "def get_grouped_params(model, no_decay=[\"bias\", \"LayerNorm.weight\"]):\n",
    "    params_with_wd, params_without_wd = [], []\n",
    "    for n, p in model.named_parameters():\n",
    "        if any(nd in n for nd in no_decay):\n",
    "            params_without_wd.append(p)\n",
    "        else:\n",
    "            params_with_wd.append(p)\n",
    "    return [\n",
    "        {\"params\": params_with_wd, \"weight_decay\": weight_decay},\n",
    "        {\"params\": params_without_wd, \"weight_decay\": 0.0},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3794252-f171-408b-9ae2-3d624e7efb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoForCausalLM(\n",
       "  (transformer): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 256)\n",
       "    (wpe): Embedding(2048, 256)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (c_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-8M')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a4d57c6-454b-4aac-9109-0ce7345f0b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoConfig {\n",
       "  \"_name_or_path\": \"roneneldan/TinyStories-8M\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPTNeoForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0,\n",
       "  \"attention_layers\": [\n",
       "    \"global\",\n",
       "    \"local\",\n",
       "    \"global\",\n",
       "    \"local\",\n",
       "    \"global\",\n",
       "    \"local\",\n",
       "    \"global\",\n",
       "    \"local\"\n",
       "  ],\n",
       "  \"attention_types\": [\n",
       "    [\n",
       "      [\n",
       "        \"global\",\n",
       "        \"local\"\n",
       "      ],\n",
       "      4\n",
       "    ]\n",
       "  ],\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"classifier_dropout\": 0.1,\n",
       "  \"embed_dropout\": 0,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_size\": 256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": null,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"gpt_neo\",\n",
       "  \"num_heads\": 16,\n",
       "  \"num_layers\": 8,\n",
       "  \"resid_dropout\": 0,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.42.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257,\n",
       "  \"window_size\": 256\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4991ff08-b54f-4d11-9c66-0408eb37fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import BeaconEmbedding, generate_beacon_attention_mask_2d\n",
    "\n",
    "if use_embedding:\n",
    "    beacon_embedding = BeaconEmbedding(embedding=model.get_input_embeddings(), vocab_size=model.config.vocab_size, n_embed=model.config.hidden_size, window_length=2)\n",
    "    model.set_input_embeddings(beacon_embedding)\n",
    "\n",
    "beacon_attention_mask = generate_beacon_attention_mask_2d(block_size, window_length=window_size, device=device)\n",
    "beacon_attention_mask = beacon_attention_mask.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_training_steps = num_epochs * len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f89030e5-3689-4acf-94b7-348f3053bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 torch.Size([64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "print(batch_size, beacon_attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0624afb0-3ca6-429e-818d-4b368f5b97ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beacon_attention_mask[0, :10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f73ae036-27f6-4504-a490-14ef4acaf506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch[\"input_ids\"], labels=batch[\"input_ids\"])\n",
    "\n",
    "        losses.append(accelerator.gather(outputs.loss))\n",
    "    loss = torch.mean(torch.cat(losses))\n",
    "    try:\n",
    "        perplexity = torch.exp(loss)\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return loss.item(), perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a83cd272-5881-426b-91c2-cf777967f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "# accelerator = Accelerator(log_with=\"wandb\")\n",
    "# accelerator.init_trackers(\n",
    "#     project_name=\"beacon_attention\",\n",
    "#     config={\"use_embedding\": use_embedding, \"use_custom_attn_mask\": use_custom_attn_mask, \"window_size\": window_size}\n",
    "# )\n",
    "\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(model, optimizer, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8f6cf88-f011-4f0d-8d19-67b66ca33dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"{'beacon_embed' if use_embedding else 'no_beacon_embed'}_{'beacon_attn_mask' if use_custom_attn_mask else 'regular_attn_mask'}_window_size_{window_size}_model\"\n",
    "output_dir = f\"./models/{model_name}\"\n",
    "if not(os.path.exists(output_dir)):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73e49375-2961-4a03-b5d0-f7e0764073b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93921320-9572-4dca-a2dd-e08261b14a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      " 50%|█████     | 1/2 [00:00<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 7454,  2402,   257,  ...,   289,  1025,   276],\n",
      "        [ 7454,  2402,   257,  ...,   531,    11,   366],\n",
      "        [ 3198,  1110,    11,  ...,  1995,   287,   262],\n",
      "        ...,\n",
      "        [ 7454,  2402,   257,  ...,  3666,  1438,   318],\n",
      "        [ 7454,  2402,   257,  ...,   262,  2818, 13209],\n",
      "        [ 7454,  2402,   257,  ...,  3061,  1625,  2081]], device='cuda:0')}\n",
      "{'input_ids': tensor([[ 7454,   612,   373,  ...,  1816,   284,  7301],\n",
      "        [ 7454,  2402,   257,  ..., 29187,   845,  2089],\n",
      "        [ 7454,  2402,   257,  ...,  8278,   510,   503],\n",
      "        ...,\n",
      "        [ 7454,  2402,   257,  ...,  6512,    11,  6184],\n",
      "        [ 7454,  2402,   257,  ..., 11316,   290,  5916],\n",
      "        [29252,  1820,   290,  ...,  1718,   262,  2657]], device='cuda:0')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "gradient_accumulation_steps = 8\n",
    "eval_steps = 5000\n",
    "\n",
    "model.train()\n",
    "\n",
    "completed_steps = 0\n",
    "step_start_time = time.perf_counter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for step, batch in tqdm(enumerate(train_dataloader, start=1), total=num_training_steps):\n",
    "        print(batch)\n",
    "        T = batch['input_ids'].shape[1] # B, T\n",
    "        if use_custom_attn_mask:\n",
    "            logits = model(input_ids=batch[\"input_ids\"], attention_mask=beacon_attention_mask).logits\n",
    "        else:\n",
    "            logits = model(input_ids=batch[\"input_ids\"]).logits\n",
    "        loss = causal_lm_loss(batch[\"input_ids\"], logits)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            step_end_time = time.perf_counter()\n",
    "            accelerator.log({\n",
    "                \"samples\": step * samples_per_step,\n",
    "                \"steps\": completed_steps,\n",
    "                \"loss/train\": loss.item() * gradient_accumulation_steps,\n",
    "                \"loss/step_time\": step_end_time - step_start_time\n",
    "            })\n",
    "            step_start_time = step_end_time\n",
    "\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        if step % gradient_accumulation_steps == 0:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            completed_steps += 1\n",
    "        if (step % (eval_steps * gradient_accumulation_steps)) == 0:\n",
    "            eval_loss, perplexity = evaluate()\n",
    "            accelerator.log(\n",
    "                {\"loss/eval\": eval_loss, \"perplexity\": perplexity}\n",
    "            )\n",
    "            model.train()\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "        \n",
    "        end_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89fdf7ff-87d9-4c34-b854-b1065044697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d8954-b7e8-42e7-a152-8cc37baf1e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
