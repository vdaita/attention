{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca481ef7-bf6a-426e-a26a-06aa7c2d0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation.utils import _crop_past_key_values\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673179f7-d66d-40bd-a07c-573c71c043b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n"
     ]
    }
   ],
   "source": [
    "# Load the model and evaluate on LongBench\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "\n",
    "ds = load_dataset(\"tianyang/repobench_python_v1.1\", split=\"cross_file_first\")\n",
    "ds = ds.select(list(range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8628d1-cb01-43a3-83df-abb3e767593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "def get_key_values_with_indices(model, past_key_values, indices):\n",
    "    new_past = []\n",
    "    if isinstance(past_key_values, DynamicCache):\n",
    "        past_key_values.batch_select_indices(indices)\n",
    "    elif past_key_values is not None:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            new_past.append(\n",
    "                (\n",
    "                    past_key_values[idx][0][:, :, indices, :],\n",
    "                    past_key_values[idx][1][:, :, indices, :],\n",
    "                )\n",
    "            )\n",
    "        past_key_values = tuple(new_past)\n",
    "    return past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04af7102-f775-4fea-a124-54d6ee7a5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punctuation_tokens(tokenizer):\n",
    "    punctuation_list = ['.', ',', ':', \"\\n\", \"\\t\", \"!\"]\n",
    "    punctuation_tokens = [idx for (idx, token) in enumerate(tokenizer.get_vocab().items()) if any(punctuation in token for punctuation in punctuation_list)]\n",
    "    return punctuation_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09189425-a47a-4f80-93e0-32a3150c858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_generate(model, tokenizer, input_ids, max_tokens=200, sink_length=8, end_length=64, window_stride=8, print_stream=False):\n",
    "    # prefill stage: load all of the inputs (since prefilling is fast, this shouldn't take too much time)\n",
    "    current_tokens = input_ids[0]\n",
    "    outputs = model(\n",
    "        input_ids,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    # print(outputs)\n",
    "    \n",
    "    # TODO: attach the generated token to the end of the current tokens\n",
    "    past_key_values = outputs.past_key_values\n",
    "\n",
    "    # build the mask\n",
    "    mask = torch.zeros(current_tokens.shape[-1], dtype=torch.bool)\n",
    "    mask[:sink_length] = 1\n",
    "    mask[-end_length:] = 1\n",
    "    mask[::window_stride] = 1\n",
    "\n",
    "    punctuation_tokens = get_punctuation_tokens(tokenizer)\n",
    "    punctuation_token_indices = [index for (index, token_id) in enumerate(current_tokens.tolist()) if token_id in punctuation_tokens]\n",
    "    mask[punctuation_token_indices] = 1\n",
    "    \n",
    "    # save the relevant ones\n",
    "    # print(mask)\n",
    "    context_positions = torch.arange(len(current_tokens))[mask]\n",
    "    context_tokens = current_tokens[mask]\n",
    "    # print(\"context position: \", context_positions, \"mask shape: \", mask.shape)\n",
    "    # print(\"past key values: \", past_key_values[0][0].shape, past_key_values[0][1].shape)\n",
    "    # past_key_values = key_values_indices(model, past_key_values, context_positions)\n",
    "    past_key_values = get_key_values_with_indices(model, past_key_values, context_positions)\n",
    "\n",
    "    new_logits = outputs.logits[:, -1:]\n",
    "    selected_tokens = new_logits.argmax(dim=-1)[0]\n",
    "    # print(current_tokens, selected_tokens)\n",
    "    current_tokens = torch.cat((current_tokens, selected_tokens), dim=-1)\n",
    "\n",
    "    # generate subsequent tokens\n",
    "    while True:\n",
    "        # check if the length is long enough, and if so, confirm whether or not the last token of the sliding window left will be staying on\n",
    "            # if so, keep the KV cache the same\n",
    "            # otherwise, prune the KV cache\n",
    "\n",
    "\n",
    "        print(\"Shape before trim: \", \"tokens: \", context_tokens.shape, \" positions: \", context_positions.shape)\n",
    "        if len(context_tokens) >= end_length:\n",
    "            if not(\n",
    "                (len(context_tokens) - end_length - 1) % window_stride == 0\n",
    "                or\n",
    "                (context_tokens[-(end_length + 1)] in punctuation_token_indices)\n",
    "                or\n",
    "                (len(context_tokens) - end_length - 1) < sink_length\n",
    "            ):\n",
    "                del_idx = len(context_tokens) - end_length - 1\n",
    "                indices_without_del = torch.cat((torch.arange(0, del_idx), torch.arange(del_idx + 1, len(context_tokens))), dim=-1)\n",
    "                past_key_values = get_key_values_with_indices(model, past_key_values, indices_without_del)\n",
    "                context_tokens = torch.cat((context_tokens[:-del_idx], context_tokens[-(del_idx - 1):]))\n",
    "                context_positions = torch.cat((context_positions[:-del_idx], context_positions[-(del_idx - 1):]))\n",
    "        print(\"Shape after trim: \", \"tokens: \", context_tokens.shape, \" positions: \", context_positions.shape)\n",
    "        \n",
    "        # print(context_positions)\n",
    "\n",
    "        print(\"Context tokens vs context positions shape: \", context_tokens.unsqueeze(0).shape, context_positions.unsqueeze(0).shape)\n",
    "        \n",
    "        outputs = model(\n",
    "            context_tokens.unsqueeze(0),\n",
    "            past_key_values=past_key_values,\n",
    "            position_ids=context_positions.unsqueeze(0)\n",
    "        )\n",
    "            \n",
    "        new_logits = outputs.logits[:, -1:][0]\n",
    "        selected_tokens = new_logits.argmax(dim=-1)\n",
    "\n",
    "        print(\"Selected tokens: \", selected_tokens)\n",
    "        \n",
    "        current_tokens = torch.cat((current_tokens, selected_tokens), dim=-1)\n",
    "        context_tokens = torch.cat((context_tokens, selected_tokens), dim=-1)\n",
    "        context_positions = torch.cat((context_positions, torch.Tensor([current_tokens.shape[-1]])), dim=-1)\n",
    "\n",
    "        if print_stream:\n",
    "            print(tokenizer.decode(current_tokens[-1]), end=\"\")\n",
    "        \n",
    "        past_key_values = outputs.past_key_values\n",
    "        \n",
    "        # calculate the next tokens  \n",
    "        if current_tokens.shape[-1] >= max_tokens:\n",
    "            break\n",
    "        if current_tokens[-1] == tokenizer.eos_token:\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(current_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95427e0d-3b7b-41d1-9b9b-51bd5e5813ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n",
      "Selected tokens:  tensor([185])\n",
      "\n",
      "Shape before trim:  tokens:  torch.Size([74])  positions:  torch.Size([74])\n",
      "Shape after trim:  tokens:  torch.Size([73])  positions:  torch.Size([73])\n",
      "Context tokens vs context positions shape:  torch.Size([1, 73]) torch.Size([1, 73])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m ds:\n\u001b[1;32m      2\u001b[0m     encoded_inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_code\u001b[39m\u001b[38;5;124m'\u001b[39m], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m----> 3\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mefficient_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoded_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(output)\n",
      "Cell \u001b[0;32mIn[7], line 64\u001b[0m, in \u001b[0;36mefficient_generate\u001b[0;34m(model, tokenizer, input_ids, max_tokens, sink_length, end_length, window_stride, print_stream)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# print(context_positions)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext tokens vs context positions shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m, context_tokens\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mshape, context_positions\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 64\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_tokens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_positions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m new_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     71\u001b[0m selected_tokens \u001b[38;5;241m=\u001b[39m new_logits\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1141\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1138\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1141\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:944\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    932\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    933\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    934\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    941\u001b[0m         position_embeddings,\n\u001b[1;32m    942\u001b[0m     )\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:693\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    696\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:253\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    251\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(down_proj)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for row in ds:\n",
    "    encoded_inputs = tokenizer.encode(row['all_code'], return_tensors=\"pt\").to(model.device)\n",
    "    output = efficient_generate(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        encoded_inputs,\n",
    "        max_tokens=encoded_inputs.shape[-1] + 50,\n",
    "        print_stream=True\n",
    "    )\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23db55ee-418b-431e-b0ee-ae50b1a17c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
